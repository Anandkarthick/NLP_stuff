{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing - twitter_samples dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with `nltk`\n",
    "\n",
    "`nltk` is the most popular Python package for Natural Language processing, it provides algorithms for importing, cleaning, pre-processing text data in human language and then apply computational linguistics algorithms like sentiment analysis.\n",
    "\n",
    "http://www.nltk.org/\n",
    "\n",
    "`nltk` also provides access to a dataset of tweets from Twitter, it includes a set of tweets already classified as negative or positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and inspect the twitter_samples dataset\n",
    "\n",
    "It also includes many easy-to-use datasets in the `nltk.corpus` package, we can download for example the `twitter_samples` package using the `nltk.download` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/anandkarthick/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"twitter_samples\")\n",
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's check the common `fileids` method of `nltk` corpora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter_samples.strings('positive_tweets.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The twitter_samples object has a `tokenized()` method that returns all tweets from a fileid already individually tokenized. Read its documentation and use it to find the number of positive and negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "number_of_positive_tweets",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "number_of_positive_tweets = len(twitter_samples.strings('positive_tweets.json'))\n",
    "print(number_of_positive_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "number_of_negative_tweets",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "number_of_negative_tweets = len(twitter_samples.strings('negative_tweets.json'))\n",
    "print(number_of_negative_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a bag-of-words model function\n",
    "\n",
    "\n",
    "The simplest model for analyzing text is just to think about text as an unordered collection of words (bag-of-words). This can generally allow to infer from the text the category, the topic or the sentiment.\n",
    "\n",
    "From the bag-of-words model we can build features to be used by a classifier, here we assume that each word is a feature that can either be `True` or `False`.\n",
    "We implement this in Python as a dictionary where for each word in a sentence we associate `True`, if a word is missing, that would be the same as assigning `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step we define a list of words that we want to filter out of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useless_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['`', '{', '|', '}', '~']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useless_words[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
       " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!',\n",
       " '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n",
       " '@97sides CONGRATS :)',\n",
       " 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "positive_tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Text in Words\n",
    "\n",
    "The first step in Natural Language processing is generally to split the text into words, this process might appear simple but it is very tedious to handle all corner cases, see for example all the issues with punctuation we have to solve if we just start with a split on whitespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_tokenized = twitter_samples.tokenized('positive_tweets.json')\n",
    "negative_tokenized = twitter_samples.tokenized('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@Lamb2ja',\n",
       " 'Hey',\n",
       " 'James',\n",
       " '!',\n",
       " 'How',\n",
       " 'odd',\n",
       " ':/',\n",
       " 'Please',\n",
       " 'call',\n",
       " 'our',\n",
       " 'Contact',\n",
       " 'Centre',\n",
       " 'on',\n",
       " '02392441234',\n",
       " 'and',\n",
       " 'we',\n",
       " 'will',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'assist',\n",
       " 'you',\n",
       " ':)',\n",
       " 'Many',\n",
       " 'thanks',\n",
       " '!']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_tokenized[:2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "build_bag_of_words_features_filtered",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Build a bag of words model\"\"\"\n",
    "    \n",
    "def build_bag_of_words_features_filtered(words):\n",
    "    return {\n",
    "        word:1 for word in words \n",
    "        if not word in useless_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'02392441234': 1,\n",
       " ':)': 1,\n",
       " ':/': 1,\n",
       " '@Lamb2ja': 1,\n",
       " 'Centre': 1,\n",
       " 'Contact': 1,\n",
       " 'Hey': 1,\n",
       " 'How': 1,\n",
       " 'James': 1,\n",
       " 'Many': 1,\n",
       " 'Please': 1,\n",
       " 'able': 1,\n",
       " 'assist': 1,\n",
       " 'call': 1,\n",
       " 'odd': 1,\n",
       " 'thanks': 1}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_bag_of_words_features_filtered(positive_tokenized[:2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of all words\n",
    "\n",
    "Before performing sentiment analysis, let's first inspect the dataset a little bit more by creating a list of all words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130099"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "for dataset in [\"positive_tweets.json\", \"negative_tweets.json\"]:\n",
    "    for tweet in twitter_samples.tokenized(dataset):\n",
    "        words.extend(tweet)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the code above, see that it is a case of nested loop, for each dataset we are looping through each tweet. Also notice we are using `extend`, how does it differ from `append`? Try it on a simple case, or read the documentation or Google for it!\n",
    "\n",
    "Now let's filter out punctuation and stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "filtered_words",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84672"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words = []\n",
    "\n",
    "for x in words:\n",
    "    if x not in useless_words:\n",
    "        filtered_words.append(x)\n",
    "len(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to filter out `useless_words` as defined in the previous section, this will reduce the lenght of the dataset by more than a factor of 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most common words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `collection` package of the standard library contains a `Counter` class that is handy for counting frequencies of words in our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also has a `most_common()` method to access the words with the higher count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "most_common_words",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "most_common_words = counter.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(':(', 4586),\n",
       " (':)', 3693),\n",
       " ('I', 2477),\n",
       " (':-)', 701),\n",
       " (':D', 658),\n",
       " ('...', 622),\n",
       " (':-(', 501),\n",
       " (\"I'm\", 456),\n",
       " ('like', 402),\n",
       " ('u', 392)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEOCAYAAACTqoDjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIgEpYAQEZGgFBAiIhKUAkJERIL6/8ZaLhxdK6CzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aed5470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sorted_word_counts = sorted(list(counter.values()), reverse=True)\n",
    "\n",
    "plt.loglog(sorted_word_counts)\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.xlabel(\"Word Rank\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the features for machine learning\n",
    "\n",
    "Using our `build_bag_of_words_features` function we can build separately the negative and positive features.\n",
    "\n",
    "The format of the positive features should be:\n",
    "\n",
    "    [\n",
    "        ( { \"here\":1, \"some\":1, \"words\":1 }, \"pos\" ),\n",
    "        ( { \"another\":1, \"tweet\":1}, \"pos\" )\n",
    "    ]\n",
    "    \n",
    "It is a list of tuples, the first element is a dictionary of the words with 1 if that word appears, the second the \"pos\" or \"neg\" string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "negative_features",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "negative_features = []\n",
    "\n",
    "for x in negative_tokenized:\n",
    "    negative_features.append([build_bag_of_words_features_filtered(x),\"neg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "positive_features",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "positive_features = []\n",
    "\n",
    "for x in positive_tokenized:\n",
    "    positive_features.append([build_bag_of_words_features_filtered(x),\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'#FollowFriday': 1,\n",
       "  ':)': 1,\n",
       "  '@France_Inte': 1,\n",
       "  '@Milipol_Paris': 1,\n",
       "  '@PKuchly57': 1,\n",
       "  'community': 1,\n",
       "  'engaged': 1,\n",
       "  'members': 1,\n",
       "  'top': 1,\n",
       "  'week': 1},\n",
       " 'pos']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{':(': 1, '@RileyMcDonough': 1, 'make': 1, 'smile': 1}, 'neg']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_features[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classifier based on the Naive Bayes algorithm. In order to find the probability for a label, this algorithm first uses the Bayes rule to express P(label|features) in terms of P(label) and P(features|label):\n",
    "\n",
    "Let's use 80% of the data for training, the rest for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(positive_features) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(positive_features[:split]+negative_features[:split])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check after training what is the accuracy on the training set, i.e. the same data used for training, we expect this to be a very high number because the algorithm already \"saw\" those data. Accuracy is the fraction of the data that is classified correctly, we can turn it into percent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "training_accuracy",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "training_accuracy = nltk.classify.util.accuracy(classifier, positive_features[:split]+negative_features[:split])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9625\n"
     ]
    }
   ],
   "source": [
    "print(training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "test_accuracy",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "test_accuracy = nltk.classify.util.accuracy(classifier, positive_features[split:]+negative_features[split:])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.35000000000001\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify({'miss': 1, '@RileyMcDonough': 1, 'Thank': 1, 'smile': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the accuracy for the test is very high, check the most informative features below to understand why:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                      :( = 1                 neg : pos    =   2362.3 : 1.0\n",
      "                      :) = 1                 pos : neg    =   1139.0 : 1.0\n",
      "                     See = 1                 pos : neg    =     37.7 : 1.0\n",
      "                     TOO = 1                 neg : pos    =     36.3 : 1.0\n",
      "                  THANKS = 1                 neg : pos    =     35.0 : 1.0\n",
      "                    THAT = 1                 neg : pos    =     27.7 : 1.0\n",
      "                    miss = 1                 neg : pos    =     26.4 : 1.0\n",
      "                     sad = 1                 neg : pos    =     25.0 : 1.0\n",
      "                     x15 = 1                 neg : pos    =     23.7 : 1.0\n",
      "                   Thank = 1                 pos : neg    =     22.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
